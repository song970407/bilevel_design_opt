{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0bc59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54b9302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['opt_action_pos', 'opt_log'])\n",
      "dict_keys(['x_trajectory_list', 'u_trajectory_list', 'log_trajectory_list'])\n"
     ]
    }
   ],
   "source": [
    "cma_es_path = 'bilevel_opt_result/cma_es/3_5.pkl'\n",
    "cma_es = pickle.load(open(cma_es_path, 'rb'))\n",
    "print(cma_es.keys())\n",
    "optimal_cma_es_path = 'bilevel_opt_result/optimal/cma_es/optimal_result_3_5.pkl'\n",
    "optimal_cma_es = pickle.load(open(optimal_cma_es_path, 'rb'))\n",
    "print(optimal_cma_es.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec34fbce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n",
      "tensor([[-0.8000,  0.8000],\n",
      "        [ 0.6759, -0.3755],\n",
      "        [-0.8000, -0.4952],\n",
      "        [ 0.4774,  0.8000],\n",
      "        [ 0.3750, -0.8000]], device='cuda:0')\n",
      "dict_keys(['total_loss_trajectory', 'position_trajectory', 'us_trajectory', 'lower_level_log_trajectory', 'best_idx', 'best_loss', 'best_position', 'best_us'])\n"
     ]
    }
   ],
   "source": [
    "opt_action_pos = cma_es['opt_action_pos']\n",
    "opt_log = cma_es['opt_log']\n",
    "print(opt_action_pos.shape)\n",
    "print(opt_action_pos)\n",
    "print(opt_log.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d004fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss_trajectory\n",
      "(100, 10)\n",
      "position_trajectory\n",
      "(100, 10, 5, 2)\n",
      "us_trajectory\n",
      "(100, 10, 160, 24, 1)\n",
      "lower_level_log_trajectory\n",
      "100\n",
      "best_idx\n",
      "99\n",
      "best_loss\n",
      "0.7135311539750546\n",
      "best_position\n",
      "torch.Size([5, 2])\n",
      "best_us\n",
      "(160, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "for key in opt_log.keys():\n",
    "    print(key)\n",
    "    if key == 'lower_level_log_trajectory':\n",
    "        print(len(opt_log[key]))\n",
    "    elif key == 'best_idx' or key == 'best_loss':\n",
    "        print(opt_log[key])\n",
    "    else:\n",
    "        print(opt_log[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc5cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['prev_graph', 'optimized_graph', 'design_opt_log'])\n",
      "dict_keys(['x_trajectory_list', 'u_trajectory_list', 'log_trajectory_list'])\n"
     ]
    }
   ],
   "source": [
    "bilevel_path = 'design_opt_experiment/bilevel/3_5/design_opt_experiment_result_ICGAT_1.0_0.pkl'\n",
    "bilevel = pickle.load(open(bilevel_path, 'rb'))\n",
    "optimal_bilevel_path = 'design_opt_experiment/bilevel/optimal/3_5/optimal_experiment_result_ICGAT_1.0_0.pkl'\n",
    "optimal_bilevel = pickle.load(open(optimal_bilevel_path, 'rb'))\n",
    "print(bilevel.keys())\n",
    "print(optimal_bilevel.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e44067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n",
      "tensor([[-0.4253, -0.7466],\n",
      "        [ 0.6062, -0.6960],\n",
      "        [ 0.3234,  0.7707],\n",
      "        [-0.7543, -0.3374],\n",
      "        [ 0.7763,  0.4259]])\n",
      "dict_keys(['total_loss_trajectory', 'position_trajectory', 'us_trajectory', 'lower_level_log_trajectory', 'best_idx', 'best_loss', 'best_position', 'best_us'])\n"
     ]
    }
   ],
   "source": [
    "print(bilevel['optimized_graph'].nodes['action'].data['pos'].shape)\n",
    "print(bilevel['optimized_graph'].nodes['action'].data['pos'])\n",
    "print(bilevel['design_opt_log'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341598c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss_trajectory\n",
      "(101,)\n",
      "position_trajectory\n",
      "(101, 5, 2)\n",
      "us_trajectory\n",
      "(101, 160, 24, 1)\n",
      "lower_level_log_trajectory\n",
      "101\n",
      "best_idx\n",
      "97\n",
      "best_loss\n",
      "1.1030357480049133\n",
      "best_position\n",
      "(5, 2)\n",
      "best_us\n",
      "(160, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "for key in bilevel['design_opt_log'].keys():\n",
    "    print(key)\n",
    "    if key == 'lower_level_log_trajectory':\n",
    "        print(len(bilevel['design_opt_log'][key]))\n",
    "    elif key == 'best_idx' or key == 'best_loss':\n",
    "        print(bilevel['design_opt_log'][key])\n",
    "    else:\n",
    "        print(bilevel['design_opt_log'][key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34217dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_names = ['bilevel']\n",
    "new_solver_names = ['implicit']\n",
    "num_x_list = [3, 4, 5]\n",
    "num_heaters_list = [5, 10, 15, 20]\n",
    "model_names = ['ICGAT', 'GAT']\n",
    "num_repeats = 10\n",
    "\n",
    "for (solver_name, new_solver_name) in zip(solver_names, new_solver_names):\n",
    "    for model_name in model_names:\n",
    "        if not os.path.exists('bilevel_opt_result/{}_{}'.format(new_solver_name, model_name)):\n",
    "            os.makedirs('bilevel_opt_result/{}_{}'.format(new_solver_name, model_name))\n",
    "        if not os.path.exists('bilevel_opt_result/optimal/{}_{}'.format(new_solver_name, model_name)):\n",
    "            os.makedirs('bilevel_opt_result/optimal/{}_{}'.format(new_solver_name, model_name))\n",
    "        for num_x in num_x_list:\n",
    "            for num_heaters in num_heaters_list:\n",
    "                design_opt_log = {}\n",
    "                design_opt_log['total_loss_trajectory'] = []\n",
    "                design_opt_log['position_trajectory'] = []\n",
    "                design_opt_log['us_trajectory'] = []\n",
    "                design_opt_log['lower_level_log_trajectory'] = []\n",
    "                design_opt_log['best_idx'] = None\n",
    "                design_opt_log['best_loss'] = float('inf')\n",
    "                design_opt_log['best_position'] = []\n",
    "                design_opt_log['best_us'] = []\n",
    "                \n",
    "                for idx in range(num_repeats):\n",
    "                    design_opt_experiment_path = 'design_opt_experiment/{}/{}_{}/design_opt_experiment_result_{}_1.0_{}.pkl'.format(solver_name, num_x, num_heaters, model_name, idx)\n",
    "                    design_opt_experiment = pickle.load(open(design_opt_experiment_path, 'rb'))['design_opt_log']                    \n",
    "                    design_opt_log['total_loss_trajectory'].append(design_opt_experiment['total_loss_trajectory'])\n",
    "                    design_opt_log['position_trajectory'].append(design_opt_experiment['position_trajectory'])\n",
    "                    design_opt_log['us_trajectory'].append(design_opt_experiment['us_trajectory'])\n",
    "                    design_opt_log['lower_level_log_trajectory'].append(design_opt_experiment['lower_level_log_trajectory'])\n",
    "                    if design_opt_experiment['best_loss'] < design_opt_log['best_loss']:\n",
    "                        design_opt_log['best_loss'] = design_opt_experiment['best_loss']\n",
    "                        design_opt_log['best_idx'] = np.array([idx, design_opt_experiment['best_idx']])\n",
    "                    design_opt_log['best_position'].append(design_opt_experiment['best_position'])\n",
    "                    design_opt_log['best_us'].append(design_opt_experiment['best_us'])\n",
    "                    \n",
    "                design_opt_log['total_loss_trajectory'] = np.stack(design_opt_log['total_loss_trajectory'], axis=1)\n",
    "                design_opt_log['position_trajectory'] = np.stack(design_opt_log['position_trajectory'], axis=1)\n",
    "                design_opt_log['us_trajectory'] = np.stack(design_opt_log['us_trajectory'], axis=1)\n",
    "                design_opt_log['best_position'].append(design_opt_experiment['best_position'])\n",
    "                design_opt_log['best_us'].append(design_opt_experiment['best_us'])\n",
    "                \n",
    "                design_opt_experiment_path = 'design_opt_experiment/{}/{}_{}/design_opt_experiment_result_{}_1.0_{}.pkl'.format(solver_name, num_x, num_heaters, model_name, design_opt_log['best_idx'][0])\n",
    "                design_opt_experiment = pickle.load(open(design_opt_experiment_path, 'rb'))\n",
    "                \n",
    "                opt_action_pos = design_opt_experiment['optimized_graph'].nodes['action'].data['pos']\n",
    "                opt_result_log = {\n",
    "                    'opt_action_pos': opt_action_pos,\n",
    "                    'design_opt_log': design_opt_log\n",
    "                }\n",
    "                saved_path = 'bilevel_opt_result/{}_{}/{}_{}.pkl'.format(new_solver_name, model_name, num_x, num_heaters)\n",
    "                pickle.dump(opt_result_log, open(saved_path, 'wb'))\n",
    "                \n",
    "                optimal_log_path = 'design_opt_experiment/{}/optimal/{}_{}/optimal_experiment_result_{}_1.0_{}.pkl'.format(solver_name, num_x, num_heaters, model_name, design_opt_log['best_idx'][0])\n",
    "                optimal_log = pickle.load(open(optimal_log_path, 'rb'))\n",
    "                \n",
    "                saved_path = 'bilevel_opt_result/optimal/{}_{}/optimal_result_{}_{}.pkl'.format(new_solver_name, model_name, num_x, num_heaters)\n",
    "                pickle.dump(optimal_log, open(saved_path, 'wb'))\n",
    "                \n",
    "                config_path = 'design_opt_experiment/{}/optimal/{}_{}/mpc_config_{}_1.0_{}.pkl'.format(solver_name, num_x, num_heaters, model_name, design_opt_log['best_idx'][0])\n",
    "                config = pickle.load(open(config_path, 'rb'))\n",
    "                \n",
    "                saved_path = 'bilevel_opt_result/optimal/{}_{}/mpc_config_{}_{}.pkl'.format(new_solver_name, model_name, num_x, num_heaters)\n",
    "                pickle.dump(config, open(saved_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "726edd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_names = ['direct']\n",
    "new_solver_names = ['single_layer']\n",
    "\n",
    "for (solver_name, new_solver_name) in zip(solver_names, new_solver_names):\n",
    "    for model_name in model_names:\n",
    "        if not os.path.exists('bilevel_opt_result/{}_{}'.format(new_solver_name, model_name)):\n",
    "            os.makedirs('bilevel_opt_result/{}_{}'.format(new_solver_name, model_name))\n",
    "        if not os.path.exists('bilevel_opt_result/optimal/{}_{}'.format(new_solver_name, model_name)):\n",
    "            os.makedirs('bilevel_opt_result/optimal/{}_{}'.format(new_solver_name, model_name))\n",
    "        for num_x in num_x_list:\n",
    "            for num_heaters in num_heaters_list:            \n",
    "                design_opt_log = {}\n",
    "                design_opt_log['total_loss_trajectory'] = []\n",
    "                design_opt_log['position_trajectory'] = []\n",
    "                design_opt_log['us_trajectory'] = []\n",
    "                design_opt_log['best_idx'] = None\n",
    "                design_opt_log['best_loss'] = float('inf')\n",
    "                design_opt_log['best_position'] = []\n",
    "                design_opt_log['best_us'] = []\n",
    "                \n",
    "                for idx in range(num_repeats):\n",
    "                    design_opt_experiment_path = 'design_opt_experiment/{}/{}_{}/design_opt_experiment_result_{}_1.0_{}.pkl'.format(solver_name, num_x, num_heaters, model_name, idx)\n",
    "                    design_opt_experiment = pickle.load(open(design_opt_experiment_path, 'rb'))['design_opt_log']                    \n",
    "                    design_opt_log['total_loss_trajectory'].append(design_opt_experiment['total_loss_trajectory'])\n",
    "                    design_opt_log['position_trajectory'].append(design_opt_experiment['position_trajectory'])\n",
    "                    design_opt_log['us_trajectory'].append(design_opt_experiment['us_trajectory'])\n",
    "                    if design_opt_experiment['best_loss'] < design_opt_log['best_loss']:\n",
    "                        design_opt_log['best_loss'] = design_opt_experiment['best_loss']\n",
    "                        design_opt_log['best_idx'] = np.array([idx, design_opt_experiment['best_idx']])\n",
    "                    design_opt_log['best_position'].append(design_opt_experiment['best_position'])\n",
    "                    design_opt_log['best_us'].append(design_opt_experiment['best_us'])\n",
    "                \n",
    "                design_opt_log['total_loss_trajectory'] = np.stack(design_opt_log['total_loss_trajectory'], axis=1)\n",
    "                design_opt_log['position_trajectory'] = np.stack(design_opt_log['position_trajectory'], axis=1)\n",
    "                design_opt_log['us_trajectory'] = np.stack(design_opt_log['us_trajectory'], axis=1)\n",
    "                design_opt_log['best_position'].append(design_opt_experiment['best_position'])\n",
    "                design_opt_log['best_us'].append(design_opt_experiment['best_us'])\n",
    "                \n",
    "                design_opt_experiment_path = 'design_opt_experiment/{}/{}_{}/design_opt_experiment_result_{}_1.0_{}.pkl'.format(solver_name, num_x, num_heaters, model_name, design_opt_log['best_idx'][0])\n",
    "                design_opt_experiment = pickle.load(open(design_opt_experiment_path, 'rb'))\n",
    "                \n",
    "                opt_action_pos = design_opt_experiment['optimized_graph'].nodes['action'].data['pos']\n",
    "                opt_result_log = {\n",
    "                    'opt_action_pos': opt_action_pos,\n",
    "                    'design_opt_log': design_opt_log\n",
    "                }                \n",
    "                saved_path = 'bilevel_opt_result/{}_{}/{}_{}.pkl'.format(new_solver_name, model_name, num_x, num_heaters)\n",
    "                pickle.dump(opt_result_log, open(saved_path, 'wb'))\n",
    "                \n",
    "                optimal_log_path = 'design_opt_experiment/{}/optimal/{}_{}/optimal_experiment_result_{}_1.0.pkl'.format(solver_name, num_x, num_heaters, model_name)\n",
    "                optimal_log = pickle.load(open(optimal_log_path, 'rb'))\n",
    "                \n",
    "                saved_path = 'bilevel_opt_result/optimal/{}_{}/optimal_result_{}_{}.pkl'.format(new_solver_name, model_name, num_x, num_heaters)\n",
    "                pickle.dump(optimal_log, open(saved_path, 'wb'))\n",
    "                \n",
    "                config_path = 'design_opt_experiment/{}/optimal/{}_{}/mpc_config_{}_1.0.pkl'.format(solver_name, num_x, num_heaters, model_name)\n",
    "                config = pickle.load(open(config_path, 'rb'))\n",
    "                \n",
    "                saved_path = 'bilevel_opt_result/optimal/{}_{}/mpc_config_{}_{}.pkl'.format(new_solver_name, model_name, num_x, num_heaters)\n",
    "                pickle.dump(config, open(saved_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86e60fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on CUDA device 1 but torch.cuda.device_count() is 1. Please use torch.load with map_location to map your storages to an existing device.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_heaters \u001b[38;5;129;01min\u001b[39;00m num_heaters_list:\n\u001b[0;32m      7\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilevel_opt_result/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(solver_name, num_x, num_heaters)\n\u001b[1;32m----> 8\u001b[0m     bilevel_opt_result \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     bilevel_opt_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt_action_pos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m bilevel_opt_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt_action_pos\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     10\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(bilevel_opt_result, \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\mpc39\\lib\\site-packages\\torch\\storage.py:218\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[1;34m(b)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_bytes\u001b[39m(b):\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\mpc39\\lib\\site-packages\\torch\\serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m    712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\mpc39\\lib\\site-packages\\torch\\serialization.py:930\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    928\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    929\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m--> 930\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    934\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\mpc39\\lib\\site-packages\\torch\\serialization.py:876\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    872\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_torch_load_uninitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     deserialized_objects[root_key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[1;32m--> 876\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    877\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    879\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m deserialized_objects[root_key]\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m view_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\mpc39\\lib\\site-packages\\torch\\serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 175\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\mpc39\\lib\\site-packages\\torch\\serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 152\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    154\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\mpc39\\lib\\site-packages\\torch\\serialization.py:143\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    141\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on CUDA device \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    144\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but torch.cuda.device_count() is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    145\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load with map_location to map your storages \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    146\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto an existing device.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m device\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on CUDA device 1 but torch.cuda.device_count() is 1. Please use torch.load with map_location to map your storages to an existing device."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "solver_name = 'cma_es'\n",
    "\n",
    "num_x_list = [3, 4, 5]\n",
    "num_heaters_list = [5, 10, 15, 20]\n",
    "for num_x in num_x_list:\n",
    "    for num_heaters in num_heaters_list:\n",
    "        path = 'bilevel_opt_result/{}/{}_{}.pkl'.format(solver_name, num_x, num_heaters)\n",
    "        bilevel_opt_result = pickle.load(open(path, 'rb'))\n",
    "        # bilevel_opt_result['opt_action_pos'] = bilevel_opt_result['opt_action_pos'].cpu().detach().numpy()\n",
    "        bilevel_opt_result['opt_log']['best_position'] = bilevel_opt_result['opt_log']['best_position'].cpu().detach().numpy()\n",
    "        pickle.dump(bilevel_opt_result, open(path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0444fa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['opt_action_pos', 'opt_log'])\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "num_x = 3\n",
    "num_heaters = 5\n",
    "path = 'bilevel_opt_result/{}/{}_{}.pkl'.format(solver_name, num_x, num_heaters)\n",
    "bilevel_opt_result = pickle.load(open(path, 'rb'))\n",
    "\n",
    "print(bilevel_opt_result.keys())\n",
    "print(type(bilevel_opt_result['opt_action_pos']))\n",
    "opt_log = bilevel_opt_result['opt_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f0c4990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss_trajectory\n",
      "<class 'numpy.ndarray'>\n",
      "position_trajectory\n",
      "<class 'numpy.ndarray'>\n",
      "us_trajectory\n",
      "<class 'numpy.ndarray'>\n",
      "lower_level_log_trajectory\n",
      "<class 'list'>\n",
      "best_idx\n",
      "<class 'int'>\n",
      "best_loss\n",
      "<class 'numpy.float64'>\n",
      "best_position\n",
      "<class 'torch.Tensor'>\n",
      "best_us\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for key in opt_log.keys():\n",
    "    print(key)\n",
    "    print(type(opt_log[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2c58345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(opt_log['best_position'].device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5cea1fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_level_log = opt_log['lower_level_log_trajectory'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7278093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_xs\n",
      "<class 'numpy.ndarray'>\n",
      "individual_loss\n",
      "<class 'numpy.ndarray'>\n",
      "total_loss\n",
      "<class 'numpy.ndarray'>\n",
      "time\n",
      "<class 'numpy.ndarray'>\n",
      "total_runtime\n",
      "<class 'float'>\n",
      "best_idx\n",
      "<class 'numpy.ndarray'>\n",
      "best_us\n",
      "<class 'numpy.ndarray'>\n",
      "best_loss\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "for key in lower_level_log.keys():\n",
    "    print(key)\n",
    "    print(type(lower_level_log[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4462f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
